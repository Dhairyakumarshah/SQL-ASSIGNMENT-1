{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install Faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcORIkoauvba",
        "outputId": "a0253611-2498-4896-c91f-b9177b791e94"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Faker in /usr/local/lib/python3.10/dist-packages (20.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from Faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "\n",
        "# Using Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Number of Book source\n",
        "n = 1200\n",
        "\n",
        "# Titles by Faker\n",
        "book_titles = [fake.catch_phrase() for _ in range(n)]\n",
        "\n",
        "# Author Names by Faker\n",
        "authors = [fake.name() for _ in range(n)]\n",
        "\n",
        "# Author Nationality by Faker\n",
        "author_nationalities = [fake.country() for _ in range(n)]\n",
        "\n",
        "# Publication Year of Book\n",
        "publication_years = np.random.randint(1990, 2023, n)\n",
        "\n",
        "# Price of the Book\n",
        "book_prices = np.random.uniform(10, 50, n).round(2)\n",
        "\n",
        "# Extra Columns for Books\n",
        "publishers = [fake.company() for _ in range(n)]  # Fake publisher names\n",
        "book_formats = np.random.choice(['Hardcover', 'Paperback', 'E-book'], n)\n",
        "availability = np.random.choice(['In Stock', 'Out of Stock'], n)\n",
        "\n",
        "# Books Ratings\n",
        "ratings = np.random.uniform(3.0, 5.0, n).round(2)\n",
        "\n",
        "# Number of Books Sold Out\n",
        "books_sold_out = np.random.randint(1000, 10000, n)\n",
        "\n",
        "# Create DataFrame for Books\n",
        "books_overall = pd.DataFrame({\n",
        "    'Title_of_Book': book_titles,\n",
        "    'Author': authors,\n",
        "    'Author_Nationality': author_nationalities,\n",
        "    'Publication_Year': publication_years,\n",
        "    'Book_Price($)': book_prices,\n",
        "    'Publisher': publishers,\n",
        "    'Format': book_formats,\n",
        "    'Availability': availability,\n",
        "})\n",
        "\n",
        "# DataFrame for the Ratings and Book Titles\n",
        "book_ratings = pd.DataFrame({\n",
        "    'Title_of_Book': book_titles,\n",
        "    'Rating': ratings,\n",
        "    'Books_Sold_Out': books_sold_out,  # New column for books sold out in book_ratings\n",
        "})\n",
        "\n",
        "# DataFrame for the Number of Pages and Book Titles\n",
        "book_pages = pd.DataFrame({\n",
        "    'Title_of_Book': book_titles,\n",
        "    'Number_of_Pages': np.random.randint(200, 800, n),\n",
        "    'Author': authors,  # Adding Author to demonstrate a composite key\n",
        "})\n",
        "\n",
        "# Remove null values\n",
        "books_overall = books_overall.dropna()\n",
        "book_ratings = book_ratings.dropna()\n",
        "book_pages = book_pages.dropna()\n",
        "\n",
        "# Print the first few rows of each DataFrame after removing null values\n",
        "print(\"Books DataFrame:\")\n",
        "print(books_overall.head().to_string(index=False))\n",
        "print(\"\\nRatings DataFrame:\")\n",
        "print(book_ratings.head().to_string(index=False))\n",
        "print(\"\\nNumber of Pages DataFrame:\")\n",
        "print(book_pages.head().to_string(index=False))\n",
        "\n",
        "# Connect to SQLite database, also creates a new file if not exists\n",
        "conn = sqlite3.connect('book_database.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create 'books_overall' table\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS books_overall (\n",
        "        Title_of_Book TEXT PRIMARY KEY,\n",
        "        Author TEXT,\n",
        "        Author_Nationality TEXT,\n",
        "        Publication_Year INTEGER,\n",
        "        Book_Price REAL,\n",
        "        Publisher TEXT,\n",
        "        Format TEXT,\n",
        "        Availability TEXT\n",
        "    )\n",
        "''')\n",
        "\n",
        "# Create 'book_ratings' table with a foreign key referencing 'books_overall'\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS book_ratings (\n",
        "        Title_of_Book TEXT PRIMARY KEY,\n",
        "        Rating REAL,\n",
        "        Books_Sold_Out INTEGER,\n",
        "        FOREIGN KEY (Title_of_Book) REFERENCES books_overall (Title_of_Book)\n",
        "    )\n",
        "''')\n",
        "\n",
        "# Create 'book_pages' table with a composite key\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS book_pages (\n",
        "        Title_of_Book TEXT,\n",
        "        Number_of_Pages INTEGER,\n",
        "        Author TEXT,\n",
        "        PRIMARY KEY (Title_of_Book, Author),\n",
        "        FOREIGN KEY (Title_of_Book) REFERENCES books_overall (Title_of_Book)\n",
        "    )\n",
        "''')\n",
        "\n",
        "# Convert DataFrames to SQLite tables\n",
        "books_overall.to_sql('books_overall', conn, index=False, if_exists='replace')\n",
        "book_ratings.to_sql('book_ratings', conn, index=False, if_exists='replace')\n",
        "book_pages.to_sql('book_pages', conn, index=False, if_exists='replace')\n",
        "\n",
        "# Commit the changes and close the connection\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "# Checking for duplicates and missing values in the 'books_overall' DataFrame\n",
        "duplicate_books_overall = books_overall[books_overall.duplicated()]\n",
        "missing_values_books_overall = books_overall.isnull().sum()\n",
        "\n",
        "# Checking for duplicates and missing values in the 'book_ratings' DataFrame\n",
        "duplicate_book_ratings = book_ratings[book_ratings.duplicated()]\n",
        "missing_values_book_ratings = book_ratings.isnull().sum()\n",
        "\n",
        "# Checking for duplicates and missing values in the 'book_pages' DataFrame\n",
        "duplicate_book_pages = book_pages[book_pages.duplicated()]\n",
        "missing_values_book_pages = book_pages.isnull().sum()\n",
        "\n",
        "# Displaying the results\n",
        "print(\"Books Overall - Duplicate Values:\")\n",
        "print(duplicate_books_overall)\n",
        "print(\"\\nBooks Overall - Missing Values:\")\n",
        "print(missing_values_books_overall)\n",
        "\n",
        "print(\"\\nBook Ratings - Duplicate Values:\")\n",
        "print(duplicate_book_ratings)\n",
        "print(\"\\nBook Ratings - Missing Values:\")\n",
        "print(missing_values_book_ratings)\n",
        "\n",
        "print(\"\\nBook Pages - Duplicate Values:\")\n",
        "print(duplicate_book_pages)\n",
        "print(\"\\nBook Pages - Missing Values:\")\n",
        "print(missing_values_book_pages)\n",
        "\n",
        "print(\"DataFrames converted to SQLite database successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3ywN9wpUxNE",
        "outputId": "a7473dc0-c1b4-48ca-faf9-a4a0b73bb811"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Books DataFrame:\n",
            "                          Title_of_Book        Author            Author_Nationality  Publication_Year  Book_Price($)                  Publisher    Format Availability\n",
            "      Decentralized foreground intranet    Louis Hays Holy See (Vatican City State)              1998          22.76                 Hardy-Diaz Hardcover     In Stock\n",
            "Multi-lateral empowering infrastructure    Anna Hanna              Saint Barthelemy              1995          26.82      Pena, Allen and Combs Hardcover Out of Stock\n",
            "  Synergized web-enabled info-mediaries Eric Castillo             Equatorial Guinea              1999          32.26 Weber, Hicks and Contreras Paperback     In Stock\n",
            "     Networked 4thgeneration capability Nathan Chavez         Palestinian Territory              2006          32.35                Beasley PLC Hardcover     In Stock\n",
            "           Synergistic secondary access  Vernon Gross                       Bermuda              1999          10.37          Contreras-Russell Hardcover Out of Stock\n",
            "\n",
            "Ratings DataFrame:\n",
            "                          Title_of_Book  Rating  Books_Sold_Out\n",
            "      Decentralized foreground intranet    4.30            6694\n",
            "Multi-lateral empowering infrastructure    3.28            6751\n",
            "  Synergized web-enabled info-mediaries    4.79            2380\n",
            "     Networked 4thgeneration capability    4.83            6676\n",
            "           Synergistic secondary access    4.68            6405\n",
            "\n",
            "Number of Pages DataFrame:\n",
            "                          Title_of_Book  Number_of_Pages        Author\n",
            "      Decentralized foreground intranet              245    Louis Hays\n",
            "Multi-lateral empowering infrastructure              394    Anna Hanna\n",
            "  Synergized web-enabled info-mediaries              746 Eric Castillo\n",
            "     Networked 4thgeneration capability              722 Nathan Chavez\n",
            "           Synergistic secondary access              219  Vernon Gross\n",
            "Books Overall - Duplicate Values:\n",
            "Empty DataFrame\n",
            "Columns: [Title_of_Book, Author, Author_Nationality, Publication_Year, Book_Price($), Publisher, Format, Availability]\n",
            "Index: []\n",
            "\n",
            "Books Overall - Missing Values:\n",
            "Title_of_Book         0\n",
            "Author                0\n",
            "Author_Nationality    0\n",
            "Publication_Year      0\n",
            "Book_Price($)         0\n",
            "Publisher             0\n",
            "Format                0\n",
            "Availability          0\n",
            "dtype: int64\n",
            "\n",
            "Book Ratings - Duplicate Values:\n",
            "Empty DataFrame\n",
            "Columns: [Title_of_Book, Rating, Books_Sold_Out]\n",
            "Index: []\n",
            "\n",
            "Book Ratings - Missing Values:\n",
            "Title_of_Book     0\n",
            "Rating            0\n",
            "Books_Sold_Out    0\n",
            "dtype: int64\n",
            "\n",
            "Book Pages - Duplicate Values:\n",
            "Empty DataFrame\n",
            "Columns: [Title_of_Book, Number_of_Pages, Author]\n",
            "Index: []\n",
            "\n",
            "Book Pages - Missing Values:\n",
            "Title_of_Book      0\n",
            "Number_of_Pages    0\n",
            "Author             0\n",
            "dtype: int64\n",
            "DataFrames converted to SQLite database successfully.\n"
          ]
        }
      ]
    }
  ]
}